{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read dictionary with municipalities\n",
    "# Com a pathlib nao precisamos ficar modificando o caminho dos arquivos, basta deixar todos no mesmo diretorio\n",
    "# muni = pd.read_csv('DTB_BRASIL_MUNICIPIO.csv',sep = ';')\n",
    "muni = pd.read_csv('/Users/andreza/reproducibility_transportation_hubs-early_warning_surveillance_systems/data/DTB_BRASIL_MUNICIPIO.csv',sep=';')    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "muni = muni[['UF', 'Nome_UF', 'Mesorregião Geográfica', 'Nome_Mesorregião',\n",
    "       'Microrregião Geográfica', 'Nome_Microrregião', 'Município',\n",
    "       'Código Município Completo', 'Nome_Município']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Adjacent matrix\n",
    "\n",
    "link = '/Users/andreza/reproducibility_transportation_hubs-early_warning_surveillance_systems/code/'\n",
    "matrix = {}\n",
    "for month in range(1, 13):\n",
    "    matrix[month] = pd.read_parquet(f'{link}adjacency_matrix_complete_{month}.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5570 entries, 1100015 to 5300108\n",
      "Columns: 5570 entries, 1100015 to 5300108\n",
      "dtypes: uint16(5570)\n",
      "memory usage: 59.2 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5570 entries, 1100015 to 5300108\n",
      "Columns: 5570 entries, 1100015 to 5300108\n",
      "dtypes: uint16(5570)\n",
      "memory usage: 59.2 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5570 entries, 1100015 to 5300108\n",
      "Columns: 5570 entries, 1100015 to 5300108\n",
      "dtypes: uint16(5570)\n",
      "memory usage: 59.2 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5570 entries, 1100015 to 5300108\n",
      "Columns: 5570 entries, 1100015 to 5300108\n",
      "dtypes: uint16(5570)\n",
      "memory usage: 59.2 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5570 entries, 1100015 to 5300108\n",
      "Columns: 5570 entries, 1100015 to 5300108\n",
      "dtypes: uint16(5570)\n",
      "memory usage: 59.2 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5570 entries, 1100015 to 5300108\n",
      "Columns: 5570 entries, 1100015 to 5300108\n",
      "dtypes: uint16(5570)\n",
      "memory usage: 59.2 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5570 entries, 1100015 to 5300108\n",
      "Columns: 5570 entries, 1100015 to 5300108\n",
      "dtypes: uint16(5570)\n",
      "memory usage: 59.2 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5570 entries, 1100015 to 5300108\n",
      "Columns: 5570 entries, 1100015 to 5300108\n",
      "dtypes: uint16(5570)\n",
      "memory usage: 59.2 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5570 entries, 1100015 to 5300108\n",
      "Columns: 5570 entries, 1100015 to 5300108\n",
      "dtypes: uint16(5570)\n",
      "memory usage: 59.2 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5570 entries, 1100015 to 5300108\n",
      "Columns: 5570 entries, 1100015 to 5300108\n",
      "dtypes: uint16(5570)\n",
      "memory usage: 59.2 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5570 entries, 1100015 to 5300108\n",
      "Columns: 5570 entries, 1100015 to 5300108\n",
      "dtypes: uint16(5570)\n",
      "memory usage: 59.2 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5570 entries, 1100015 to 5300108\n",
      "Columns: 5570 entries, 1100015 to 5300108\n",
      "dtypes: uint16(5570)\n",
      "memory usage: 59.2 MB\n"
     ]
    }
   ],
   "source": [
    "df_matrix = {}\n",
    "for month in range(1, 13):\n",
    "    df_matrix = matrix[month].astype('uint16')\n",
    "    df_matrix.info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hubs = pd.read_csv('lists_of_hubs.csv')\n",
    "hubs = pd.read_csv('/Users/andreza/reproducibility_transportation_hubs-early_warning_surveillance_systems/data/lists_of_hubs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_muni_vertice = pd.DataFrame(matrix[7].columns, columns=['muni'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mname(n):\n",
    "    \n",
    "    m = link_muni_vertice.iloc[n]['muni']\n",
    "    set_muni = muni[muni['Código Município Completo'] == m].reset_index()\n",
    "    return [set_muni.iloc[0]['Nome_Município'],set_muni.iloc[0]['Nome_UF'],m]\n",
    "   \n",
    "#def get_mnumber(name):\n",
    "#    muni[muni['Nome_Município'] == name]\n",
    "#    \n",
    "#    co_mu = muni[muni['Nome_Município'] == name].reset_index()['Código Município Completo'][0]\n",
    "#    muni_number = link_muni_vertice[link_muni_vertice['muni'] == co_mu]['muni'].index.tolist()[0]\n",
    "#    return [muni_number, co_mu]\n",
    "\n",
    "def get_mnumber(name,uf):\n",
    "    \n",
    "    set_df = muni[(muni['Nome_Município'] == name) & (muni['Nome_UF'] == uf)].reset_index()\n",
    "    \n",
    "    co_mu = set_df['Código Município Completo'][0]\n",
    "    \n",
    "    muni_number = link_muni_vertice[link_muni_vertice['muni'] == co_mu]['muni'].index.tolist()[0]\n",
    "    \n",
    "    return [muni_number, co_mu]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mnumber_of_set(df_col):\n",
    "    muni_number = []\n",
    "\n",
    "    for i in range(0,len(df_col)):\n",
    "    \n",
    "        uf = df_col['Nome_UF'].iloc[i]\n",
    "    \n",
    "        city = df_col['Nome_Município'].iloc[i]\n",
    "    \n",
    "        muni_number.append(get_mnumber(city,uf)[0])\n",
    "    \n",
    "    return muni_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python program for implementation\n",
    "# of Ford Fulkerson algorithm\n",
    "from collections import defaultdict\n",
    "\n",
    "# This class represents a directed graph\n",
    "# using adjacency matrix representation\n",
    "        \n",
    "class Graph:\n",
    "\n",
    "    def __init__(self, graph):\n",
    "        self.graph = graph # residual graph\n",
    "        self. ROW = len(graph)\n",
    "        # self.COL = len(gr[0])\n",
    "\n",
    "\n",
    "    '''Returns true if there is a path from source 's' to sink 't' in\n",
    "    residual graph. Also fills parent[] to store the path '''\n",
    "\n",
    "\n",
    "    def BFS(self, s, t, parent):\n",
    "        visited = [False] * self.ROW\n",
    "        queue = []\n",
    "        queue.append(s)\n",
    "        visited[s] = True\n",
    "\n",
    "        while queue:\n",
    "            u = queue.pop(0)\n",
    "            for ind, val in enumerate(self.graph[u]):\n",
    "                if visited[ind] == False and val > 0:\n",
    "                    queue.append(ind)\n",
    "                    visited[ind] = True\n",
    "                    parent[ind] = u\n",
    "                    if ind == t:\n",
    "                        return True\n",
    "        return False\n",
    "\n",
    "    def FordFulkerson(self, source, sink):\n",
    "        parent = [-1] * self.ROW\n",
    "        max_flow = 0\n",
    "        paths = []  # List to store the paths\n",
    "        value_path = []\n",
    "\n",
    "        while self.BFS(source, sink, parent):\n",
    "            path_flow = float(\"inf\")\n",
    "            s = sink\n",
    "            while s != source:\n",
    "                path_flow = min(path_flow, self.graph[parent[s]][s])\n",
    "                s = parent[s]\n",
    "\n",
    "            max_flow += path_flow\n",
    "\n",
    "            # Store the current path\n",
    "            current_path = []\n",
    "            v = sink\n",
    "            while v != source:\n",
    "                u = parent[v]\n",
    "                current_path.append((u, v))\n",
    "                self.graph[u][v] -= path_flow\n",
    "                self.graph[v][u] += path_flow\n",
    "                v = parent[v]\n",
    "            paths.append(current_path)\n",
    "            value_path.append(max_flow)\n",
    "            \n",
    "            if len(current_path) > 3:\n",
    "                break\n",
    "\n",
    "        df_paths = pd.DataFrame(paths).transpose()\n",
    "        return max_flow, df_paths,value_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the list of municipalities as the origen and destination to run the FF method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "selec_hubs = hubs[hubs['hub_inter'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Nome_UF</th>\n",
       "      <th>UF2</th>\n",
       "      <th>co_ibge</th>\n",
       "      <th>Nome_Município</th>\n",
       "      <th>ind_proxi</th>\n",
       "      <th>ind_intermed</th>\n",
       "      <th>ind_proxi_per</th>\n",
       "      <th>ind_intermed_per</th>\n",
       "      <th>grau</th>\n",
       "      <th>densidade_2022</th>\n",
       "      <th>populacao_2022</th>\n",
       "      <th>ones</th>\n",
       "      <th>hub_ind_proxi</th>\n",
       "      <th>hub_ind_intermed</th>\n",
       "      <th>hub_density</th>\n",
       "      <th>hub_inter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Pará</td>\n",
       "      <td>15</td>\n",
       "      <td>1502954</td>\n",
       "      <td>Eldorado do Carajás</td>\n",
       "      <td>0.350491</td>\n",
       "      <td>0.000296</td>\n",
       "      <td>35.049146</td>\n",
       "      <td>0.029642</td>\n",
       "      <td>104.0</td>\n",
       "      <td>9.53</td>\n",
       "      <td>28192</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Tocantins</td>\n",
       "      <td>17</td>\n",
       "      <td>1702554</td>\n",
       "      <td>Augustinópolis</td>\n",
       "      <td>0.333847</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>33.384663</td>\n",
       "      <td>0.031884</td>\n",
       "      <td>37.0</td>\n",
       "      <td>44.97</td>\n",
       "      <td>17484</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Maranhão</td>\n",
       "      <td>21</td>\n",
       "      <td>2108207</td>\n",
       "      <td>Pedreiras</td>\n",
       "      <td>0.346127</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>34.612683</td>\n",
       "      <td>0.012277</td>\n",
       "      <td>36.0</td>\n",
       "      <td>141.38</td>\n",
       "      <td>37050</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Paraíba</td>\n",
       "      <td>25</td>\n",
       "      <td>2517001</td>\n",
       "      <td>Umbuzeiro</td>\n",
       "      <td>0.314568</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>31.456761</td>\n",
       "      <td>0.008081</td>\n",
       "      <td>15.0</td>\n",
       "      <td>49.17</td>\n",
       "      <td>9124</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Bahia</td>\n",
       "      <td>29</td>\n",
       "      <td>2926301</td>\n",
       "      <td>Riachão do Jacuípe</td>\n",
       "      <td>0.376729</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>37.672899</td>\n",
       "      <td>0.024668</td>\n",
       "      <td>49.0</td>\n",
       "      <td>28.90</td>\n",
       "      <td>33386</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    Nome_UF  UF2  co_ibge       Nome_Município  ind_proxi  \\\n",
       "1           1       Pará   15  1502954  Eldorado do Carajás   0.350491   \n",
       "2           2  Tocantins   17  1702554       Augustinópolis   0.333847   \n",
       "4           4   Maranhão   21  2108207            Pedreiras   0.346127   \n",
       "7           7    Paraíba   25  2517001            Umbuzeiro   0.314568   \n",
       "9           9      Bahia   29  2926301   Riachão do Jacuípe   0.376729   \n",
       "\n",
       "   ind_intermed  ind_proxi_per  ind_intermed_per   grau  densidade_2022  \\\n",
       "1      0.000296      35.049146          0.029642  104.0            9.53   \n",
       "2      0.000319      33.384663          0.031884   37.0           44.97   \n",
       "4      0.000123      34.612683          0.012277   36.0          141.38   \n",
       "7      0.000081      31.456761          0.008081   15.0           49.17   \n",
       "9      0.000247      37.672899          0.024668   49.0           28.90   \n",
       "\n",
       "   populacao_2022  ones  hub_ind_proxi  hub_ind_intermed  hub_density  \\\n",
       "1           28192     1            0.0               1.0          0.0   \n",
       "2           17484     1            0.0               1.0          0.0   \n",
       "4           37050     1            0.0               1.0          1.0   \n",
       "7            9124     1            0.0               1.0          0.0   \n",
       "9           33386     1            1.0               1.0          0.0   \n",
       "\n",
       "   hub_inter  \n",
       "1        1.0  \n",
       "2        1.0  \n",
       "4        1.0  \n",
       "7        1.0  \n",
       "9        1.0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selec_hubs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "selec_hubs = selec_hubs.assign(muni_number = get_mnumber_of_set(selec_hubs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selec_hubs = selec_hubs[selec_hubs.Nome_UF == 'Amazonas']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UF = 'Acre'\n",
    "# ac_muni = muni[muni.Nome_UF == UF]\n",
    "# path_folder = Path(f'FF_path_results_{UF}')\n",
    "# path_folder.mkdir(exist_ok=True)\n",
    "\n",
    "#choosing a municipality\n",
    "ac_muni = muni[muni.Nome_Município == 'Manaus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac_muni = ac_muni.assign(muni_number = get_mnumber_of_set(ac_muni))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UF</th>\n",
       "      <th>Nome_UF</th>\n",
       "      <th>Mesorregião Geográfica</th>\n",
       "      <th>Nome_Mesorregião</th>\n",
       "      <th>Microrregião Geográfica</th>\n",
       "      <th>Nome_Microrregião</th>\n",
       "      <th>Município</th>\n",
       "      <th>Código Município Completo</th>\n",
       "      <th>Nome_Município</th>\n",
       "      <th>muni_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>13</td>\n",
       "      <td>Amazonas</td>\n",
       "      <td>3</td>\n",
       "      <td>Centro Amazonense</td>\n",
       "      <td>7</td>\n",
       "      <td>Manaus</td>\n",
       "      <td>2603</td>\n",
       "      <td>1302603</td>\n",
       "      <td>Manaus</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     UF   Nome_UF  Mesorregião Geográfica   Nome_Mesorregião  \\\n",
       "111  13  Amazonas                       3  Centro Amazonense   \n",
       "\n",
       "     Microrregião Geográfica Nome_Microrregião  Município  \\\n",
       "111                        7            Manaus       2603   \n",
       "\n",
       "     Código Município Completo Nome_Município  muni_number  \n",
       "111                    1302603         Manaus          111  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ac_muni.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run method for the list of municipalities selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 , 1391 , 1391\n"
     ]
    }
   ],
   "source": [
    "lst1 = list(ac_muni['muni_number']) #[52,53,54,55,56,58,59,60,61,62,63,64,65,66,67,68,69,71,72,73]\n",
    "lst2 = list(selec_hubs['muni_number'])#[57,67,70, 108,119,111,102,91]#list(range(1,5570,1))\n",
    "\n",
    "print(len(lst1), ',', len(lst2), ',', len(lst1)*len(lst2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#choosing the number of MONTH\n",
    "# Recife [1/4],  Manaus [7/4], Salvador[1/5],SP [1/ 6], Rio [12/6]\n",
    "\n",
    "df_matrix_np = matrix[7].to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to process each value in parallel\n",
    "def process_value(value):\n",
    "    n, m = value\n",
    "\n",
    "    #matrix = pd.read_parquet(link0, engine='pyarrow')\n",
    "    #df_np = matrix.to_numpy()\n",
    "    \n",
    "    #com o df em .copy() não precisamos ler/carregar o arquivo varias vezes\n",
    "    g = Graph(df_matrix_np.copy())\n",
    "\n",
    "    max_flow, df_paths, value_path = g.FordFulkerson(n, m)\n",
    "    \n",
    "    # evitar a escrita de arquivos vazios, o que tbm reduz o tempo de execução\n",
    "    \n",
    "    if len(value_path)==0:\n",
    "        return\n",
    "    \n",
    "    #create output data frame\n",
    "   \n",
    "\n",
    "    lists = [df_paths[col].tolist() for col in df_paths]\n",
    "    \n",
    "    path_value = pd.DataFrame(value_path, columns=['value_cum'])\n",
    "    path_value = path_value.assign(value=path_value['value_cum'] - path_value['value_cum'].shift())\n",
    "    path_value['value'] = path_value['value'].fillna(0)\n",
    "    path_value['ori_muni_name'] = get_mname(n)[0]\n",
    "    path_value['ori_uf_name'] = get_mname(n)[1]\n",
    "    path_value['ori_co_ibge'] = get_mname(n)[2]\n",
    "    path_value['des_muni_name'] = get_mname(m)[0]\n",
    "    path_value['des_uf_name'] = get_mname(m)[1]\n",
    "    path_value['des_co_ibge'] = get_mname(m)[2]\n",
    "    path_value = path_value.assign(paths=lists)\n",
    "    \n",
    "    \n",
    "    #save_output\n",
    "    \n",
    "    table2 = pa.Table.from_pandas(path_value)\n",
    "\n",
    "    string2 = str(get_mname(n)[2]) + '_' + str(get_mname(m)[2]) + '_' + 'path_value'\n",
    "\n",
    "    path_to_save2 = '/Users/andreza/Downloads/FF_path_results_Manaus_7/{}.parquet'.format(string2)\n",
    "\n",
    "    pq.write_table(table2, path_to_save2)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 234 µs, sys: 14 µs, total: 248 µs\n",
      "Wall time: 264 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create a list of values to process\n",
    "list_orig_dest = [(x, y) for x in lst1 for y in lst2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Create a ThreadPoolExecutor to run the processing function in parallel\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:\n",
    "    executor.map(process_value, list_orig_dest)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#em andamento\n",
    "# def create_output_dataframe(path_value, df_paths, n, m):\n",
    "#     lists = [df_paths[col].tolist() for col in df_paths]\n",
    "    \n",
    "#     path_value = pd.DataFrame(value_path, columns=['value_cum'])\n",
    "#     path_value = path_value.assign(value=path_value['value_cum'] - path_value['value_cum'].shift())\n",
    "#     path_value['value'] = path_value['value'].fillna(0)\n",
    "#     path_value['ori_muni_name'] = get_mname(n)[0]\n",
    "#     path_value['ori_uf_name'] = get_mname(n)[1]\n",
    "#     path_value['ori_co_ibge'] = get_mname(n)[2]\n",
    "#     path_value['des_muni_name'] = get_mname(m)[0]\n",
    "#     path_value['des_uf_name'] = get_mname(m)[1]\n",
    "#     path_value['des_co_ibge'] = get_mname(m)[2]\n",
    "#     path_value = path_value.assign(paths=lists)\n",
    "    \n",
    "#     return path_value\n",
    "    \n",
    "    \n",
    "# def save_output(n, m, path_value):\n",
    "    \n",
    "#     table2 = pa.Table.from_pandas(path_value)\n",
    "\n",
    "#     string2 = str(get_mname(n)[2]) + '_' + str(get_mname(m)[2]) + '_' + 'path_value'\n",
    "\n",
    "#     #path_to_save2 = path_folder/f'{string2}.parquet'\n",
    "#     #path_to_save2 = path_folder/'{}.parquet'.format(string2)\n",
    "#     path_to_save2 = '/Users/andreza/Downloads/FF_path_results_Acre/{}.parquet'.format(string2)\n",
    "\n",
    "#     pq.write_table(table2, path_to_save2)\n",
    "    \n",
    "\n",
    "# # Define a function to process each value in parallel\n",
    "# def process_value(value):\n",
    "#     n, m = value\n",
    "\n",
    "#     #matrix = pd.read_parquet(link0, engine='pyarrow')\n",
    "#     #df_np = matrix.to_numpy()\n",
    "    \n",
    "#     #com o df em .copy() não precisamos ler/carregar o arquivo varias vezes\n",
    "#     g = Graph(df_np.copy())\n",
    "\n",
    "#     max_flow, df_paths, value_path = g.FordFulkerson(n, m)\n",
    "#     #podemos utilizar esse trecho se quisermos evitar a escrita de arquivos vazios\n",
    "#     if len(value_path)==0:\n",
    "#         return\n",
    "    \n",
    "#     #create output data frame\n",
    "#     df_values = create_output_dataframe(value_path, df_paths, n, m)\n",
    "#     save_output(n, m, path_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#original\n",
    "# for value in [(x, y) for x in lst1 for y in lst2]:#zip(lst1,lst2):\n",
    "#     n,m = value\n",
    "    \n",
    "#     #Part 1 - carregando os dados da matriz\n",
    "#     #start_time = timeit.default_timer()\n",
    "    \n",
    "#     matrix = pd.read_parquet(link0, engine='pyarrow')\n",
    "#     df_np = matrix.to_numpy()\n",
    "    \n",
    "#     #elapsed = timeit.default_timer() - start_time\n",
    "#     #print(\"Part 1: \" + str(elapsed))    \n",
    "\n",
    "#     #Part 2 - gerando o grafo\n",
    "#     #start_time = timeit.default_timer()\n",
    "#     graph = df_np\n",
    "#     g = Graph(graph)\n",
    "#     #elapsed = timeit.default_timer() - start_time\n",
    "#     #print(\"Part 2: \" + str(elapsed))\n",
    "    \n",
    "#     #Part 3 chamada FF\n",
    "#     #start_time = timeit.default_timer()\n",
    "#     max_flow, df_paths, value_path = g.FordFulkerson(n, m)\n",
    "    \n",
    "#     #elapsed = timeit.default_timer() - start_time\n",
    "#     #print(\"Part 3: \" + str(elapsed))\n",
    "    \n",
    "    \n",
    "#     #Part 4\n",
    "#     #start_time = timeit.default_timer()\n",
    "#     # transform df int a variable of lists\n",
    "#     lists = [df_paths[col].tolist() for col in df_paths]\n",
    "\n",
    "#     #elapsed = timeit.default_timer() - start_time\n",
    "#     #print(\"Part 4: \" + str(elapsed))\n",
    "    \n",
    "#     #Part 5 - criando output\n",
    "#     #start_time = timeit.default_timer()\n",
    "    \n",
    "#     #format value_path\n",
    "#     path_value = pd.DataFrame(value_path, columns=['value_cum'])\n",
    "#     path_value = path_value.assign(value = path_value['value_cum']-path_value['value_cum'].shift())\n",
    "#     path_value['value'] = path_value['value'].fillna(0)\n",
    "#     #path_value['value'].iloc[0] = path_value['value_cum'].iloc[0]\n",
    "#     path_value['ori_muni_name'] = get_mname(n)[0]\n",
    "#     path_value['ori_uf_name'] = get_mname(n)[1]\n",
    "#     path_value['ori_co_ibge'] = get_mname(n)[2]\n",
    "#     path_value['des_muni_name'] = get_mname(m)[0]\n",
    "#     path_value['des_uf_name'] = get_mname(m)[1]\n",
    "#     path_value['des_co_ibge'] = get_mname(m)[2]\n",
    "#     #add lists to path_value\n",
    "#     path_value = path_value.assign(paths = lists)\n",
    "    \n",
    "#     #path_value.value[0] = path_value.value_cum[0]\n",
    "    \n",
    "#     # Save df_paths\n",
    "#     #table1 = pa.Table.from_pandas(df_paths)\n",
    "\n",
    "#     #string1 = str(get_mname(n)[2]) + '_' + str(get_mname(m)[2]) + '_' + 'path'\n",
    "\n",
    "#     #path_to_save1 = '../FF_path_results_Acre/{}.parquet'.format(string1)\n",
    "\n",
    "#     #pq.write_table(table1, path_to_save1)\n",
    "    \n",
    "#     #save path_value\n",
    "    \n",
    "#     table2 = pa.Table.from_pandas(path_value)\n",
    "\n",
    "#     string2 = str(get_mname(n)[2]) + '_' + str(get_mname(m)[2]) + '_' + 'path_value'\n",
    "\n",
    "#     path_to_save2 = '/Users/andreza/Downloads/FF_path_results_RJ/{}.parquet'.format(string2)\n",
    "\n",
    "#     pq.write_table(table2, path_to_save2)\n",
    "    \n",
    "#     #elapsed = timeit.default_timer() - start_time\n",
    "#     #print(\"Part 5: \" + str(elapsed))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
